# *********************************************************************************************************************
# Title     : 10 Feature Selection Overview
# Objective : TODO
# Created by: Owner
# Created on: 2020/8/16
# URL       : http://www.feat.engineering/selection.html
# *********************************************************************************************************************


# ＜ポイント＞
# - これまでの章の特徴量エンジニアリングはデータの予測力を引き出すための処理
# - 予測モデリングでは関係のない特徴量を除外することも重要な処理
#   --- 特徴量選択 / 特徴量フィルタリング


# ＜目次＞
# 10.1 特徴量選択のゴール
# 10.2 特徴量選択の方法論
# 10.3 無関係な特徴量の影響
# 10.4 予測子へのオーバーフィット
# 10.5 ケーススタディ




# # 10.1 特徴量選択のゴール ---------------------------------------




# 10.3 無関係な特徴量の影響 ---------------------------------------


# - 無関係な予測子はモデルをどれほど傷つけますか？
#   --- それはモデルのタイプ
#   --- 予測子の性質
#   --- 予測子の数に対するトレーニングセットのサイズの比率（別名、p：n比率）



# ＜シミュレーション＞
# - データセットに無関係な特徴量を投入した場合のモデル精度の劣化度合い
#   --- X軸： ノイズ特徴量
#   --- Y軸： RMSE
#   --- ファセット(縦) ： データ数(500 or 1000)
#   --- ファセット(横) ： モデル種別


# ＜線形モデル＞
# - 全体的に他のモデルほど極端なパフォーマンス劣化は見られないかった
# - 線形回帰はノイズ特徴量の増加に対して線形的にのパフォーマンスが浸食された
#   --- サイズが500⇒1000に増加するにつれて改善した（p：n比が根本的な問題である可能性が示唆される）
# - glmnetは正則化のペナルティによりノイズ特徴量の増加に対して頑健なパフォーマンスを返した



# ＜非線形モデル＞
# - kNN(k近傍法)は全体的にパフォーマンスが低く、ノイズ特徴量の影響は中程度のものとなった
# - MARSのパフォーマンスは良好、モデル固有の特徴量選択によりノイズに対する良好な耐性を示した
# - SVMや単層NNはノイズ特徴量がない場合は良好だったが、ノイズ特徴量で急速にパフォーマンスが劣化した




# 10.4 予測子へのオーバーフィット -------------------------------------------






